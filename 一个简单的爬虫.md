# 一个简单的爬虫

源码在`spiders`文件夹下。爬虫使用`threading`模块编写。

## 参考：

主要参考了下面的博客：

* [用python爬虫抓站的一些技巧总结](http://python.jobbole.com/81997/)，原文链接[obmem.info](http://obmem.info/?p=476)

其它值得一读的相关博客：

* [Parallelism in one line](http://chriskiehl.com/article/parallelism-in-one-line/)

## 如何多线程

使用队列+线程的组合：
```python
from threading import Thread
from Queue import Queue

class Spider:
    def __init__(self,q_req=None, q_res=None, threads):
        self.q_req = Queue()
        self.q_res = Queue()
        for i in xrange(0,threads):
            t = Thread(target=self.get_page)
            t.setDaemon(True)
            t.start()
    def get_page(self):
        while True:
            req = self.q_req.get()
            do something
            self.q_req.task_done()
```
这样只需要给队列不断的添加url，就可以了。

## 其它

该文档和源码将会持续更新。